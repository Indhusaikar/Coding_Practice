{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8230ed4-1ed3-4a10-9c23-0746dbc1e293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7c8697-cb11-4da2-9102-8c2e299232ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ecc7cc-6f56-42a2-b413-c7d5fe6f728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SHAPE = (200, 200)  # Resize all images to this shape for MobileNetV2\n",
    "BATCH_SIZE = 100\n",
    "DATA_DIR = 'G:/Datasets/Medicinal Leaf dataset_30/'  # Update with your dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd5f5e7-cccd-4784-b90d-4af183ca9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = pathlib.Path(DATA_DIR)\n",
    "categories = os.listdir(DATA_DIR)\n",
    "mleaf_images_dict = {}\n",
    "mleaf_labels_dict = {}\n",
    "X, y = [], []\n",
    "for index, category in enumerate(categories):\n",
    "   mleaf_images_dict[category] = list(data_dir.glob(category + '/*'))\n",
    "   mleaf_labels_dict[category] = index\n",
    "\n",
    "for category_name, images in mleaf_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img, IMAGE_SHAPE)\n",
    "        X.append(resized_img)\n",
    "        y.append(mleaf_labels_dict[category_name])\n",
    "\n",
    "X = np.array(X) / 255.0  # Normalize images\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c501d3a-ced5-4cba-a791-52086b6b6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'Aloevera': 118 images\n",
      "Class 'Amla': 67 images\n",
      "Class 'Amruthaballi': 91 images\n",
      "Class 'Arali': 89 images\n",
      "Class 'ashoka': 81 images\n",
      "Class 'Astma_weed': 82 images\n",
      "Class 'Badipala': 76 images\n",
      "Class 'Balloon_Vine': 61 images\n",
      "Class 'Bamboo': 118 images\n",
      "Class 'Beans': 97 images\n",
      "Class 'Betel': 114 images\n",
      "Class 'Bhrami': 104 images\n",
      "Class 'Bringaraja': 73 images\n",
      "Class 'camphor': 66 images\n",
      "Class 'Caricature': 76 images\n",
      "Class 'Castor': 129 images\n",
      "Class 'Catharanthus': 134 images\n",
      "Class 'Chakte': 68 images\n",
      "Class 'Chilly': 69 images\n",
      "Class 'Citron lime (herelikai)': 99 images\n",
      "Class 'Coffee': 83 images\n",
      "Class 'Common rue(naagdalli)': 67 images\n",
      "Class 'Coriender': 115 images\n",
      "Class 'Curry': 168 images\n",
      "Class 'Doddpathre': 142 images\n",
      "Class 'Drumstick': 56 images\n",
      "Class 'Ekka': 81 images\n",
      "Class 'Eucalyptus': 80 images\n",
      "Class 'Ganigale': 75 images\n",
      "Class 'Ganike': 63 images\n",
      "Class 'Gasagase': 79 images\n",
      "Class 'Ginger': 82 images\n"
     ]
    }
   ],
   "source": [
    "# Count images per class\n",
    "class_counts = {category: len(images) for category, images in mleaf_images_dict.items()}\n",
    "\n",
    "# Print counts for each class\n",
    "for category, count in class_counts.items():\n",
    "    print(f\"Class '{category}': {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22151ee8-c780-499b-84c0-cd9a9982fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2903 images with shape (2903, 200, 200, 3) and 2903 labels.\n",
      "X shape: (2903, 200, 200, 3), y shape: (2903,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(X)} images with shape {X.shape} and {len(y)} labels.\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af983d33-78e1-4930-81f1-c1fdf4fec8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c0d2f2a-9550-4101-aed9-1ea2fb9d9cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 2322 (2322, 200, 200, 3) samples (79.99%)\n",
      "Testing data: 581 (581, 200, 200, 3) samples (20.01%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentages\n",
    "train_percentage = len(X_train) / len(X) * 100\n",
    "test_percentage = len(X_test) / len(X) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training data: {len(X_train)} {X_train.shape} samples ({train_percentage:.2f}%)\")\n",
    "print(f\"Testing data: {len(X_test)} {X_test.shape} samples ({test_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6143b76a-d445-4ade-91a2-6d1942a6ac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Indhu\\AppData\\Local\\Temp\\ipykernel_1684\\327665529.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model_mobilenet = MobileNetV2(input_shape=IMAGE_SHAPE + (3,), include_top=False, weights='imagenet')\n"
     ]
    }
   ],
   "source": [
    "base_model_mobilenet = MobileNetV2(input_shape=IMAGE_SHAPE + (3,), include_top=False, weights='imagenet')\n",
    "base_model_mobilenet.trainable = False  # Freeze the convolutional base\n",
    "\n",
    "feature_extractor_mobilenet = Sequential([\n",
    "    base_model_mobilenet,\n",
    "    GlobalAveragePooling2D()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "114f5646-9314-456a-8d72-25ebffdf3171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features using MobileNetV2\n",
    "import time\n",
    "start_trainfeatures_time = time.time()\n",
    "X_train_features = feature_extractor_mobilenet.predict(X_train, batch_size=BATCH_SIZE, verbose=1)  \n",
    "end_trainfeatures_time = time.time()\n",
    "start_testfeatures_time = time.time()\n",
    "X_test_features = feature_extractor_mobilenet.predict(X_test, batch_size=BATCH_SIZE, verbose=1) \n",
    "end_testfeatures_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59aa39dc-9241-468b-b727-5386d3d0ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 83.82622647285461 seconds\n",
      "Testing time: 12.70110011100769 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate time taken for training and testing\n",
    "train_time = end_trainfeatures_time - start_trainfeatures_time\n",
    "test_time = end_testfeatures_time - start_testfeatures_time\n",
    "print(f\"Training time: {train_time} seconds\")\n",
    "print(f\"Testing time: {test_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18d6e9cf-953b-413a-af66-f001ac7d9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Support Vector Machine\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0aae5a16-b25f-4646-a381-d1e73d6c005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Random Forest Accuracy: 0.8055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        22\n",
      "           1       0.88      0.54      0.67        13\n",
      "           2       0.86      0.86      0.86        22\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       0.90      0.83      0.86        23\n",
      "           5       0.82      0.67      0.74        21\n",
      "           6       0.79      0.79      0.79        19\n",
      "           7       1.00      0.56      0.71         9\n",
      "           8       0.65      0.77      0.71        22\n",
      "           9       0.91      0.87      0.89        23\n",
      "          10       0.74      1.00      0.85        17\n",
      "          11       1.00      0.86      0.93        22\n",
      "          12       0.80      0.73      0.76        11\n",
      "          13       1.00      0.88      0.94        17\n",
      "          14       0.94      1.00      0.97        16\n",
      "          15       0.85      1.00      0.92        28\n",
      "          16       0.66      0.95      0.78        22\n",
      "          17       0.88      0.44      0.58        16\n",
      "          18       0.67      0.50      0.57         8\n",
      "          19       0.87      0.59      0.70        22\n",
      "          20       0.82      0.69      0.75        13\n",
      "          21       1.00      0.73      0.84        11\n",
      "          22       0.74      0.94      0.83        18\n",
      "          23       0.48      0.84      0.61        32\n",
      "          24       0.89      0.89      0.89        35\n",
      "          25       1.00      1.00      1.00        11\n",
      "          26       0.69      0.75      0.72        12\n",
      "          27       0.94      0.94      0.94        18\n",
      "          28       1.00      0.85      0.92        20\n",
      "          29       0.67      0.75      0.71         8\n",
      "          30       1.00      0.24      0.38        17\n",
      "          31       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.81       581\n",
      "   macro avg       0.84      0.78      0.79       581\n",
      "weighted avg       0.84      0.81      0.80       581\n",
      "\n",
      "Evaluating Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.9312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        22\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.92      1.00      0.96        22\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       0.96      1.00      0.98        23\n",
      "           5       0.90      0.90      0.90        21\n",
      "           6       0.78      0.95      0.86        19\n",
      "           7       0.89      0.89      0.89         9\n",
      "           8       0.88      0.95      0.91        22\n",
      "           9       1.00      1.00      1.00        23\n",
      "          10       1.00      0.94      0.97        17\n",
      "          11       0.95      0.86      0.90        22\n",
      "          12       0.91      0.91      0.91        11\n",
      "          13       1.00      0.94      0.97        17\n",
      "          14       0.94      1.00      0.97        16\n",
      "          15       1.00      1.00      1.00        28\n",
      "          16       0.87      0.91      0.89        22\n",
      "          17       1.00      0.75      0.86        16\n",
      "          18       1.00      0.88      0.93         8\n",
      "          19       0.83      0.86      0.84        22\n",
      "          20       0.86      0.92      0.89        13\n",
      "          21       0.91      0.91      0.91        11\n",
      "          22       0.90      1.00      0.95        18\n",
      "          23       0.90      0.88      0.89        32\n",
      "          24       0.94      0.94      0.94        35\n",
      "          25       1.00      1.00      1.00        11\n",
      "          26       0.85      0.92      0.88        12\n",
      "          27       1.00      1.00      1.00        18\n",
      "          28       1.00      0.95      0.97        20\n",
      "          29       1.00      0.88      0.93         8\n",
      "          30       0.86      0.71      0.77        17\n",
      "          31       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.93       581\n",
      "   macro avg       0.93      0.93      0.93       581\n",
      "weighted avg       0.93      0.93      0.93       581\n",
      "\n",
      "Evaluating K-Nearest Neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Indhu\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\Indhu\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Indhu\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Indhu\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\Indhu\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy: 0.8451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        22\n",
      "           1       0.62      0.77      0.69        13\n",
      "           2       0.95      0.82      0.88        22\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       0.81      0.91      0.86        23\n",
      "           5       0.70      0.76      0.73        21\n",
      "           6       0.84      0.84      0.84        19\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.86      0.86      0.86        22\n",
      "           9       0.92      1.00      0.96        23\n",
      "          10       0.94      1.00      0.97        17\n",
      "          11       0.82      0.82      0.82        22\n",
      "          12       0.50      0.82      0.62        11\n",
      "          13       0.94      1.00      0.97        17\n",
      "          14       0.94      1.00      0.97        16\n",
      "          15       1.00      0.96      0.98        28\n",
      "          16       0.57      0.91      0.70        22\n",
      "          17       0.75      0.38      0.50        16\n",
      "          18       0.71      0.62      0.67         8\n",
      "          19       0.88      0.68      0.77        22\n",
      "          20       0.73      0.62      0.67        13\n",
      "          21       1.00      1.00      1.00        11\n",
      "          22       0.90      1.00      0.95        18\n",
      "          23       0.86      0.75      0.80        32\n",
      "          24       0.87      0.74      0.80        35\n",
      "          25       0.85      1.00      0.92        11\n",
      "          26       0.79      0.92      0.85        12\n",
      "          27       1.00      1.00      1.00        18\n",
      "          28       1.00      1.00      1.00        20\n",
      "          29       1.00      0.50      0.67         8\n",
      "          30       0.82      0.53      0.64        17\n",
      "          31       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.85       581\n",
      "   macro avg       0.85      0.84      0.83       581\n",
      "weighted avg       0.86      0.85      0.84       581\n",
      "\n",
      "Evaluating Support Vector Machine...\n",
      "Support Vector Machine Accuracy: 0.9294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        22\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       0.95      0.95      0.95        22\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       0.96      0.96      0.96        23\n",
      "           5       0.86      0.90      0.88        21\n",
      "           6       0.82      0.95      0.88        19\n",
      "           7       1.00      0.78      0.88         9\n",
      "           8       0.83      0.91      0.87        22\n",
      "           9       1.00      1.00      1.00        23\n",
      "          10       1.00      1.00      1.00        17\n",
      "          11       0.96      1.00      0.98        22\n",
      "          12       1.00      1.00      1.00        11\n",
      "          13       1.00      0.94      0.97        17\n",
      "          14       1.00      1.00      1.00        16\n",
      "          15       1.00      1.00      1.00        28\n",
      "          16       0.83      0.91      0.87        22\n",
      "          17       1.00      0.69      0.81        16\n",
      "          18       1.00      0.88      0.93         8\n",
      "          19       0.86      0.86      0.86        22\n",
      "          20       0.92      0.85      0.88        13\n",
      "          21       1.00      0.91      0.95        11\n",
      "          22       0.86      1.00      0.92        18\n",
      "          23       0.77      0.94      0.85        32\n",
      "          24       1.00      0.94      0.97        35\n",
      "          25       1.00      1.00      1.00        11\n",
      "          26       0.92      0.92      0.92        12\n",
      "          27       1.00      1.00      1.00        18\n",
      "          28       1.00      0.95      0.97        20\n",
      "          29       0.88      0.88      0.88         8\n",
      "          30       0.92      0.65      0.76        17\n",
      "          31       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.93       581\n",
      "   macro avg       0.94      0.92      0.93       581\n",
      "weighted avg       0.93      0.93      0.93       581\n",
      "\n",
      "Evaluating Decision Tree...\n",
      "Decision Tree Accuracy: 0.3219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.23      0.25        22\n",
      "           1       0.08      0.08      0.08        13\n",
      "           2       0.11      0.09      0.10        22\n",
      "           3       0.65      0.69      0.67        16\n",
      "           4       0.53      0.35      0.42        23\n",
      "           5       0.14      0.14      0.14        21\n",
      "           6       0.44      0.42      0.43        19\n",
      "           7       0.22      0.44      0.30         9\n",
      "           8       0.45      0.45      0.45        22\n",
      "           9       0.26      0.26      0.26        23\n",
      "          10       0.33      0.35      0.34        17\n",
      "          11       0.40      0.27      0.32        22\n",
      "          12       0.29      0.36      0.32        11\n",
      "          13       0.67      0.35      0.46        17\n",
      "          14       0.56      0.56      0.56        16\n",
      "          15       0.58      0.54      0.56        28\n",
      "          16       0.31      0.41      0.35        22\n",
      "          17       0.30      0.38      0.33        16\n",
      "          18       0.17      0.25      0.20         8\n",
      "          19       0.09      0.09      0.09        22\n",
      "          20       0.12      0.15      0.14        13\n",
      "          21       0.25      0.27      0.26        11\n",
      "          22       0.40      0.44      0.42        18\n",
      "          23       0.27      0.25      0.26        32\n",
      "          24       0.39      0.37      0.38        35\n",
      "          25       0.67      0.55      0.60        11\n",
      "          26       0.13      0.25      0.17        12\n",
      "          27       0.37      0.39      0.38        18\n",
      "          28       0.17      0.10      0.12        20\n",
      "          29       0.08      0.12      0.10         8\n",
      "          30       0.18      0.12      0.14        17\n",
      "          31       0.50      0.53      0.51        17\n",
      "\n",
      "    accuracy                           0.32       581\n",
      "   macro avg       0.32      0.32      0.32       581\n",
      "weighted avg       0.34      0.32      0.32       581\n",
      "\n",
      "Evaluating Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.7608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        22\n",
      "           1       0.80      0.62      0.70        13\n",
      "           2       0.48      0.68      0.57        22\n",
      "           3       0.94      0.94      0.94        16\n",
      "           4       0.95      0.87      0.91        23\n",
      "           5       0.61      0.67      0.64        21\n",
      "           6       0.71      0.89      0.79        19\n",
      "           7       0.75      0.67      0.71         9\n",
      "           8       0.64      0.82      0.72        22\n",
      "           9       1.00      0.83      0.90        23\n",
      "          10       0.85      0.65      0.73        17\n",
      "          11       0.89      0.73      0.80        22\n",
      "          12       0.70      0.64      0.67        11\n",
      "          13       0.93      0.82      0.88        17\n",
      "          14       1.00      1.00      1.00        16\n",
      "          15       0.93      1.00      0.97        28\n",
      "          16       0.81      0.77      0.79        22\n",
      "          17       0.80      0.75      0.77        16\n",
      "          18       0.67      0.75      0.71         8\n",
      "          19       0.60      0.55      0.57        22\n",
      "          20       0.75      0.69      0.72        13\n",
      "          21       1.00      0.73      0.84        11\n",
      "          22       0.70      0.89      0.78        18\n",
      "          23       0.48      0.69      0.56        32\n",
      "          24       0.88      0.80      0.84        35\n",
      "          25       1.00      0.55      0.71        11\n",
      "          26       0.57      0.67      0.62        12\n",
      "          27       1.00      0.78      0.88        18\n",
      "          28       0.82      0.70      0.76        20\n",
      "          29       0.54      0.88      0.67         8\n",
      "          30       0.64      0.41      0.50        17\n",
      "          31       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.76       581\n",
      "   macro avg       0.78      0.75      0.76       581\n",
      "weighted avg       0.79      0.76      0.76       581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifiers using test set\n",
    "for model_name, model in classifiers.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    start_train_time = time.time()\n",
    "    model.fit(X_train_features, y_train)\n",
    "    end_train_time = time.time()\n",
    "    start_test_time = time.time() \n",
    "    y_pred = model.predict(X_test_features)\n",
    "    end_test_time = time.time()\n",
    "    print(f\"{model_name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d72b3cb-773d-4977-b0da-d3fe92444578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.04194474220275879 seconds\n",
      "Testing time: 0.422954797744751 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate time taken for training and testing\n",
    "train_time = end_train_time - start_train_time\n",
    "test_time = end_test_time - start_test_time\n",
    "print(f\"Training time: {train_time} seconds\")\n",
    "print(f\"Testing time: {test_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d788002-dbf4-454d-b3b6-4dc3792bb938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross Validation for Random Forest...\n",
      "Average Accuracy: 0.7705\n",
      "Average Precision: 0.7844\n",
      "Average Recall: 0.7705\n",
      "Average F1 Score: 0.7631\n",
      "\n",
      "K-Fold Cross Validation for Logistic Regression...\n",
      "Average Accuracy: 0.9031\n",
      "Average Precision: 0.9100\n",
      "Average Recall: 0.9031\n",
      "Average F1 Score: 0.9024\n",
      "\n",
      "K-Fold Cross Validation for K-Nearest Neighbors...\n",
      "Average Accuracy: 0.8157\n",
      "Average Precision: 0.8307\n",
      "Average Recall: 0.8157\n",
      "Average F1 Score: 0.8123\n",
      "\n",
      "K-Fold Cross Validation for Support Vector Machine...\n",
      "Average Accuracy: 0.8893\n",
      "Average Precision: 0.8993\n",
      "Average Recall: 0.8893\n",
      "Average F1 Score: 0.8877\n",
      "\n",
      "K-Fold Cross Validation for Decision Tree...\n",
      "Average Accuracy: 0.3532\n",
      "Average Precision: 0.3608\n",
      "Average Recall: 0.3532\n",
      "Average F1 Score: 0.3493\n",
      "\n",
      "K-Fold Cross Validation for Naive Bayes...\n",
      "Average Accuracy: 0.7446\n",
      "Average Precision: 0.7674\n",
      "Average Recall: 0.7446\n",
      "Average F1 Score: 0.7436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifiers using k-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"K-Fold Cross Validation for {clf_name}...\")\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_features, y_train):\n",
    "        X_train_fold, X_val_fold = X_train_features[train_index], X_train_features[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = clf.predict(X_val_fold)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "        precision_scores.append(precision_score(y_val_fold, y_val_pred, average='weighted'))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_val_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_val_fold, y_val_pred, average='weighted'))\n",
    "\n",
    "    print(f\"Average Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "    print(f\"Average Precision: {np.mean(precision_scores):.4f}\")\n",
    "    print(f\"Average Recall: {np.mean(recall_scores):.4f}\")\n",
    "    print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe728ca2-9b53-4292-bb66-ab5e05d2336b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
